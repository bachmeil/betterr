<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>index</title>
  <style type="text/css">code{white-space: pre;}</style>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/water.css">
<style>html{margin-top: -60px;}</style>

</head>
<body>
<div class="container"><br><br>
<h1 id="d-as-a-better-r">D as a Better R</h1>
<p>This project is a collection of the things I’ve been doing since 2013 that connect the D and R languages.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> There are also some libraries that can be used in cases where efficiency is critical. The intended audience is an academic researcher doing the type of data analysis that gets done with R or Python, but who has a preference to write their program in D, whether for speed, static typing, or the nice features of the language. Even though the intended audience is academic researchers doing empirical work, it is likely to be of interest to anyone doing statistical analysis, and to many others doing scientific and numerical computing in software such as Matlab.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>The emphasis is on functionality and the speed with which you can write correct code. When this conflicts with performance, I’ve been willing to let my programs run for a little bit longer. I want to minimize the learning curve as much as possible. For instance, one design goal is that you don’t need to know anything about memory allocation, memory management, or garbage collection. As soon as you introduce those requirements, you’ve lost almost the entire community of academic researchers, and the ones that persevere are likely to get things wrong and waste a lot of time not doing the analysis they’re supposed to be doing. I’m not targeting C++ or Rust programmers, who will surely be repulsed by the focus on getting work done and the absence of premature optimization.</p>
<p>My earlier focus was on writing D functions and calling them from R, motivated by what Rcpp had done for C++ usage. My <a href="https://github.com/bachmeil/embedrv2">embedrv2</a> project makes this easy by using metaprogramming to write the bindings for you. Over time I’ve come to the conclusion that this is the wrong direction for interoperability. I want to write complete programs in D, not R programs with a few bottlenecks rewritten in D. The approach I’ve taken is to treat the full R language as a library called by my D program. My D programs have full access to everything in base R, all packages, all libraries with an R interface…literally everything you get with R is available in D, in a fully seamless fashion that feels like it’s D all the way down.</p>
<p>Now, there are certainly some downsides to this. You have to write wrappers over R. A few things are inherently slower once you involve R, so you need to rewrite those pieces in D or find a library in another language that does what you need. You have to link to shared libraries. I had to learn how the R internals work in order to build the lowest-level foundation for interoperability.</p>
<h1 id="data-sharing">Data Sharing</h1>
<p>The starting point for interoperability is data sharing. I needed a way to create, access, and manipulate R data structures from D. I needed to work with data frames, vectors, matrices, lists, and so on from my D program, but they had to simultaneously be available to R. This was not a trivial undertaking. Three things would be required for this to be practical:</p>
<ul>
<li>Allocation of data structures. This is easy. All of R’s data structures are a single C struct under the hood. You can send a string of code to R and then capture the output, which is a pointer, or you can directly call functions in libR.so, which do the allocation and return a pointer. The only differences in the two approaches are that the latter is faster and the former creates a variable inside R that can be passed as an argument to R functions.</li>
<li>Releasing the data structures to the R garbage collector when they’re no longer in use. It’s easy to <em>protect</em> objects from the garbage collector. What’s more difficult is to recognize when they’re no longer needed and remove the protection exactly once. Failure to unprotect creates a memory leak, unprotecting too soon results in segfaults, and unprotecting twice kills your program. I implemented a reference counting approach to handle all of these memory management issues. To my knowledge, all of the bugs have been worked out. It’s been a long time since I had any issues related to memory. I’m currently moving from the reference counting system I implemented myself to <code>SafeRefCounted</code>. If there are any remaining issues I don’t know about, transitioning to <code>SafeRefCounted</code>, which wasn’t around when I wrote my reference counting code, should fix them.</li>
<li>Convenient access to the data from D. Working out the allocation and garbage collection for matrix isn’t terribly helpful if you still need to work with individual elements using pointer arithmetic. It’s only sustainable if you have syntax like <code>m[1,4] = 3.2</code>, <code>m[2..6, 0..3] = 4.0</code>, and <code>m[1,3..$]</code>. Once you have that, you can build on it with things like <code>Row(m,2) = [3.6, -1.1, -2.4, 4.8]</code>. These conveniences don’t take much time individually, but there are many of them, and comprehensively testing all of them and fixing bugs is a slow process for a side project.</li>
</ul>
<h1 id="running-r-code-and-calling-r-functions">Running R Code and Calling R Functions</h1>
<p>Once I had the data sharing under control, I needed a way to tell R what to do. The simplest version of this is passing a string of R code to the R shared library, having it evaluate the code, and returning a pointer to the output (if any). In other cases, you’re calling the C functions that R calls under the hood, where you pass R data structures as arguments and receive an R data structure as the output. Finally, you can call R packages that provide an interface to C, C++, or Fortran code directly. This is the same as calling C functions, but you have to find and link to the shared library for that package, as every R package with compiled code has its own shared library.</p>
<h1 id="bottlenecks">Bottlenecks</h1>
<p>Although your program is probably going to be more than fast enough out of the box, <a href="efficiency.html">as I wrote about here</a>, there will be cases in which it’s worth your while to speed things up. The leading example is a simulation that’s repeated many times. Parallel random number generation and optimized linear algebra libraries are an essential part of the toolbox for simulation. I’ve done three things to facilitate this:</p>
<ul>
<li>Ported one of L’Ecuyer’s parallel random number generators from Java to D.</li>
<li>Stripped out the random number generators for most of the distributions in the GNU Scientific Library and polish them so they can be compiled with ImportC.</li>
<li>Stripped the matrix library in Gretl into its a standalone library and got it compiling with ImportC.</li>
</ul>
<p>Other optimizations have been implemented. I recommend reading <a href="efficiency.html">the discussion here</a> for more on this topic. If worst comes to worst, you always have the options to rewrite bottlenecks in D or to call any available library with a C interface. I want to emphasize that this should not usually be necessary. You should be able to write your program and not worry about the speed.</p>
<h1 id="documentation">Documentation</h1>
<p>This is always tough. It takes a long time to write good documentation.</p>
<h1 id="im-sharing-my-work">I’m Sharing My Work</h1>
<p>Please note that I view this as <em>sharing my work</em> rather than <em>releasing a library</em>. I’m showing you what has worked for me, and giving you the details of my workflow, but it’s not polished like a well-run open source project. Maybe others will see the value and pitch in. If not, well, I’ll continue to use it and update it as I do. I’m largely indifferent on adoption, but I would be happy if someone else found it valuable, even if I’m not going to go out of my way to make that happen.</p>
<h1 id="how-does-this-compare-to-project-x">How Does This Compare To Project X?</h1>
<p>There have been many previous efforts on this front. There have been statistical libraries and optimization libraries and plotting libraries and so on. Mir is an impressive project with some great pieces.</p>
<p>The problem with that approach is that there will never be a pure D solution that’s remotely suitable for the day-to-day work of a data analyst. It’s simply too big of a task to write everything from scratch in D, and honestly, it’s pointless to do so. Reusing code written in other languages was never a problem for R, Python, or any other community, so why not do the same thing for D?</p>
<p>This project intends to provide a complete solution for the data analyst. One of the goals is a convenient, efficient D solution for <em>any</em> data analysis you’d want to do. Once you discard the silly objections to calling other languages that are prevalent in the D community (seriously, D even compiles C code!) it’s not that big of a task. D can give you access to</p>
<ul>
<li>Everything written in D, C, and Fortran.</li>
<li>Everything written in/for R (you can treat R as a shared library and call any of its packages).</li>
<li>Everything written in Python and Julia (you can reuse the bridges that have been created to work with R).</li>
<li>Anything written in C++ that has an R interface, which includes thousands of packages, and since R interfaces are just C interfaces, you can actually reuse that infrastructure to call most C++ libraries.</li>
</ul>
<p>There are limitations, perhaps, but it would be silly to argue D is not a viable choice for the vast majority of data analysis being done in 2024.</p>
<h1 id="better-r">Better R?</h1>
<p>Walter Bright has referred to a particular use case for D as “better C”, sometimes jokingly calling it <a href="https://dlang.org/blog/2018/06/11/dasbetterc-converting-make-c-to-d/">DasBetterC</a>. Although the use case is somewhat different, the name “better R” is a reasonable description of what I’m doing with this project:</p>
<ul>
<li>All of R is available to a D program (you can run arbitrary R code, capture the output, and access it from D, most of the time without any copying).</li>
<li>You can rewrite R programs in D, sprinkling in D features where they add convenience or speed.</li>
<li>You can modify the behavior of R where you don’t like it. One of the things I wish R did differently is dropping dimensions. A row of a matrix will silently become a vector, with a completely different interpretation. That doesn’t happen when I access the matrix from D.</li>
<li>You add D’s static typing to R. You can’t imagine how good that is given that R is not only a dynamic language, but that it was developed at the same place that gave us C. (Both were created at Bell Labs. The first release of S was four years after the first release of C. Both of them having single-letter names was not an accident.)</li>
<li>You can use D’s compile time features on top of a vanilla R program.</li>
</ul>
<h1 id="getting-started">Getting Started</h1>
<p>Probably the best way to figure out what is going on is to look at the example and then look at the tests linked in the next section. After that, you can read the other documentation. You can also start a discussion on the Github repo if you have questions or wonder how to do something.</p>
<p>In the meantime, here’s a short example to give you an idea of what to expect:</p>
<pre><code>void main() {
  // Initialization
  startR();
  // Generate 100 draws from a N(0.5, sd=0.1) distribution
  Vector x = rnorm(100, 0.5, 0.1);
  // Create a 3x2 matrix and fill the columns
  auto m = Matrix(3,2);
  Column(m,0) = [1.1, 2.2, 3.3];
  Column(m,1) = [4.4, 5.5, 6.6];
  // Calculate the inverse of the transpose
  auto m2 = solve(t(m));
  // Modify the second and third elements of the first column of m
  m[1..$,0] = [7.7, 8.8];
  // Choose x and y to minimize x^2 + y^2
  // Use Nelder-Mead with initial guesses 3.5 and -5.5
  auto nm = NelderMead(&amp;f);
  OptimSolution sol = nm.solve([3.5, -5.5]);
  // Clean up
  closeR();
}

extern(C) {
  double f(int n, double * par, void * ex) {
    return par[0]*par[0] + par[1]*par[1];
  }
}</code></pre>
<h1 id="usage">Usage</h1>
<ul>
<li><a href="installation.html">Installation</a></li>
<li><a href="compiling.html">Compiling</a></li>
<li><a href="example.html">Example</a></li>
<li><a href="https://github.com/bachmeil/betterr/tree/main/testing">Tests demonstrating most of the functionality</a></li>
</ul>
<h1 id="modules">Modules</h1>
<ul>
<li><a href="base.html">betterr.baser</a></li>
<li><a href="matrix.html">betterr.matrix</a></li>
<li><a href="vector.html">betterr.vector</a></li>
<li><a href="random.html">betterr.random</a></li>
<li><a href="ts.html">betterr.ts</a></li>
<li><a href="optim.html">betterr.optim</a></li>
<li><a href="plot.html">betterr.plot</a></li>
<li><a href="array.html">betterr.array</a></li>
<li><a href="dataframe.html">betterr.dataframe</a></li>
<li><a href="list.html">betterr.list</a></li>
<li><a href="lm.html">betterr.lm</a></li>
<li><a href="api.html">Pieces of the R API</a></li>
<li><a href="quadprog.html">Quadratic programming</a></li>
</ul>
<h1 id="notes-on-various-topics">Notes on Various Topics</h1>
<ul>
<li><a href="wsl.html">Using betterr with WSL</a></li>
<li><a href="evalr.html">Evaluating arbitrary R code</a></li>
<li><a href="databases.html">Accessing databases</a></li>
<li><a href="randomscalar.html">Generating scalar random variables efficiently</a></li>
<li><a href="prng.html">Parallel random number generation</a></li>
<li><a href="parallelrun.html">Running Better R programs in parallel</a></li>
<li><a href="openblas.html">Using OpenBLAS for matrix calculations</a></li>
<li><a href="matrixpackage.html">Calling the Matrix package from D</a></li>
<li><a href="setvar.html">Passing an existing variable from D into R</a></li>
<li><a href="lazycopy.html">R lazy copying</a></li>
<li><a href="arglists.html">Understanding argument lists in the R source</a></li>
<li><a href="funcptr.html">Passing function pointers around</a></li>
<li><a href="gslrng.html">Using the GSL to generate random numbers sequentially or in parallel</a></li>
<li><a href="numerical.html">Options for numerical programming in D</a></li>
<li><a href="importc.html">Compiling With ImportC</a></li>
</ul>
<h1 id="thoughts">Thoughts</h1>
<ul>
<li><a href="efficiency.html">Efficiency</a></li>
<li><a href="scaling.html">Scaling to Zero</a></li>
<li><a href="improve.html">Some Ways To Improve This Project</a></li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>I released an earlier project called embedr, and even wrote <a href="https://dlang.org/blog/2020/01/27/d-for-data-science-calling-r-from-d/">a blog post about it for the D blog</a>. The latest version of that project <a href="https://github.com/bachmeil/embedrv2">can be found here</a>. While that project only made available a fraction of the things I’d done to that point.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Although performance is suitable for most uses, it does not and never will provide the fastest code possible. You’ll want to look at libraries such as Mir if that’s your goal, because this project doesn’t have much to offer you on that dimension.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

<br>
<a href="index.html">Index</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/bachmeil/betterr">Repo</a>
</div>
<br><br>
</body>
</html>
